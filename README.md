
# Introduction to Databricks
Use the labs in this repo to get started with Spark in Azure Databricks.

Start by following the [Setup Guide](Setup%20Guide.pdf) to prepare your Azure environment and download the [labfiles](Databricks_Labs.zip) used in the lab exercises. Then complete the labs in the following order:
1. [Lab 1 - Getting Started with Spark](Lab%201%20-%20Getting%20Started%20with%20Spark.pdf). In this lab you'll learn how to provision a Spark cluster in an Azure Databricks workspace, and use it to analyze data interactively using Python or Scala.
2. [Lab 2 - Running a Spark Job](Lab%202%20-%20Running%20a%20Spark%20Job.pdf). In this lab, you'll learn how to configure a Spark job for unattended execution so that you can schedule batch processing workloads.
3. [Lab 3 - Using Structured Streaming](Lab%203%20-%20Using%20Structured%20Streaming.pdf). In this lab you'll learn how to use Spark to process an unbounded stream of realtime data; a common requirement in Internet-of-Things (IoT) scenarios.
4. [Lab 4 - Introduction to Machine Learning](Lab%204%20-%20Introduction%20to%20Machine%20Learning.pdf). In this lab you'll get started with machine learning by using Spark to train and evaluate a classification model.

